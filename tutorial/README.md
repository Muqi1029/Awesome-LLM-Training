# Tutorial

This part introduces a tutorial for basic knowledge of LLM training.

1. Distributed Training
2. Parallel Techniques
    1. Model Parallelism
    2. Expert Parallel
    3. Data Parallelism
3. Framework Usgae
    1. Torch
    2. Accelerate
    3. DeepSpeed
    4. Megatron-LM
    5. LLaMA-Factory
    6. OpenRLHF
    7. Ray
    8. veRL
4. Examples

## Model Parallelism
